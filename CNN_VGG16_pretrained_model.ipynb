{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame created successfully with 384 records!\n",
      "Found 268 validated image filenames belonging to 2 classes.\n",
      "Found 58 validated image filenames belonging to 2 classes.\n",
      "Found 58 validated image filenames belonging to 2 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 1us/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\PYTHON\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59s/step - accuracy: 0.5035 - loss: 12.3717  \n",
      "Epoch 1: val_loss improved from inf to 12.33282, saving model to restnet50_best_model.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 65s/step - accuracy: 0.5066 - loss: 12.3720 - val_accuracy: 0.4483 - val_loss: 12.3328\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\PYTHON\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\PYTHON\\Lib\\site-packages\\keras\\src\\callbacks\\model_checkpoint.py:206: UserWarning: Can save best model only with val_loss available, skipping.\n",
      "  self._save_model(epoch=epoch, batch=None, logs=logs)\n",
      "c:\\PYTHON\\Lib\\site-packages\\keras\\src\\callbacks\\early_stopping.py:155: UserWarning: Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: accuracy,loss\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31s/step - accuracy: 0.4647 - loss: 12.4805 \n",
      "Epoch 3: val_loss did not improve from 12.33282\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 35s/step - accuracy: 0.4631 - loss: 12.4784 - val_accuracy: 0.4483 - val_loss: 12.3347\n",
      "Epoch 4/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35s/step - accuracy: 0.4682 - loss: 12.4345 \n",
      "Epoch 5: val_loss did not improve from 12.33282\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 38s/step - accuracy: 0.4660 - loss: 12.4376 - val_accuracy: 0.4483 - val_loss: 12.3451\n",
      "Epoch 6/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39s/step - accuracy: 0.4749 - loss: 12.4436 \n",
      "Epoch 7: val_loss did not improve from 12.33282\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 43s/step - accuracy: 0.4772 - loss: 12.4433 - val_accuracy: 0.4483 - val_loss: 12.3497\n",
      "Epoch 8/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37s/step - accuracy: 0.5167 - loss: 12.4115 \n",
      "Epoch 9: val_loss did not improve from 12.33282\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 41s/step - accuracy: 0.5170 - loss: 12.4094 - val_accuracy: 0.4483 - val_loss: 12.3556\n",
      "Epoch 10/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 742ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33s/step - accuracy: 0.5794 - loss: 12.3742 \n",
      "Epoch 11: val_loss did not improve from 12.33282\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 37s/step - accuracy: 0.5743 - loss: 12.3785 - val_accuracy: 0.4483 - val_loss: 12.3637\n",
      "Epoch 12/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49s/step - accuracy: 0.5227 - loss: 12.4342 \n",
      "Epoch 13: val_loss did not improve from 12.33282\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 53s/step - accuracy: 0.5221 - loss: 12.4365 - val_accuracy: 0.4483 - val_loss: 12.3714\n",
      "Epoch 14/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 208ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52s/step - accuracy: 0.4261 - loss: 12.5237 \n",
      "Epoch 15: val_loss did not improve from 12.33282\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 57s/step - accuracy: 0.4322 - loss: 12.5173 - val_accuracy: 0.4483 - val_loss: 12.3683\n",
      "Epoch 16/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 427ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52s/step - accuracy: 0.4560 - loss: 12.4713 \n",
      "Epoch 17: val_loss did not improve from 12.33282\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 56s/step - accuracy: 0.4565 - loss: 12.4745 - val_accuracy: 0.4483 - val_loss: 12.3772\n",
      "Epoch 18/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 271ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37s/step - accuracy: 0.5123 - loss: 12.4030 \n",
      "Epoch 19: val_loss did not improve from 12.33282\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 42s/step - accuracy: 0.5115 - loss: 12.4070 - val_accuracy: 0.4483 - val_loss: 12.3898\n",
      "Epoch 20/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 258ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54s/step - accuracy: 0.4764 - loss: 12.4836 \n",
      "Epoch 21: val_loss did not improve from 12.33282\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 59s/step - accuracy: 0.4835 - loss: 12.4698 - val_accuracy: 0.4483 - val_loss: 12.3835\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - accuracy: 0.5517 - loss: 12.2867\n",
      "Test accuracy: 55.17%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense,Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n",
    "\n",
    "data_set_dir = 'D:/Tea Withering project/tea leaves'\n",
    "batch_size = 64\n",
    "img_size = (224, 224)\n",
    "valid_image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "\n",
    "\n",
    "image_files = [f for f in os.listdir(data_set_dir) if f.lower().endswith(tuple(valid_image_extensions))]\n",
    "\n",
    "if len(image_files) == 0:\n",
    "    print(\"No valid image files found in the dataset directory.\")\n",
    "else:\n",
    "    # Create DataFrame\n",
    "    data = {\n",
    "        'id': image_files,\n",
    "        'label': np.random.randint(0, 2, len(image_files))  #Random labels for demonstration\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    df['label'] = df['label'].astype(str)\n",
    "    print(f\"DataFrame created successfully with {len(df)} records!\")\n",
    "\n",
    "    train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "    if len(train_df) == 0 or len(val_df) == 0 or len(test_df) == 0:\n",
    "     raise ValueError(\"One of the train, validation, or test sets is empty. Check your dataset splitting.\")\n",
    "    \n",
    "    val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Image Data Augmentation for Training\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=50,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    brightness_range=[0.7,1.3]\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=data_set_dir,\n",
    "    x_col='id',\n",
    "    y_col='label',\n",
    "    target_size=img_size,\n",
    "    class_mode='binary',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=data_set_dir,\n",
    "    x_col='id',\n",
    "    y_col='label',\n",
    "    target_size=img_size,\n",
    "    class_mode='binary',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "\n",
    "test_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=data_set_dir,\n",
    "    x_col='id',\n",
    "    y_col='label',\n",
    "    target_size=img_size,\n",
    "    class_mode='binary',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False  # No need to shuffle test data\n",
    ")\n",
    "\n",
    "# Load VGG16 base model without the top layers\n",
    "resnet50_base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom classification layers\n",
    "x = GlobalAveragePooling2D()(resnet50_base.output)\n",
    "x = Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=resnet50_base.input, outputs=output)\n",
    "\n",
    "# Freeze the layers of VGG16 to prevent them from being trained\n",
    "for layer in resnet50_base.layers[-8:]:   #unfreeze the last 4 layers for the fine tuning       \n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-6), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Set up a checkpoint to save the best model during training and for regularozation for adjusting learinig rate dynamically\n",
    "checkpoint = ModelCheckpoint('restnet50_best_model.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-7)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    epochs=100,\n",
    "    callbacks=[checkpoint,early_stopping]\n",
    ")\n",
    "\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=len(test_generator))\n",
    "print(f'Test accuracy: {test_acc * 100:.2f}%')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
